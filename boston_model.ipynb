{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "from flask import jsonify\n",
    "import json\n",
    "\n",
    "# Ignores warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict containing information regarding iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Feature/Target names\n",
    "feature_names = [x[:-5] for x in iris['feature_names']]\n",
    "target_name = 'species'\n",
    "\n",
    "# Split iris data into X/y/df\n",
    "X = pd.DataFrame(iris['data'], columns=feature_names) # removes ' (cm)' suffix on end of column names\n",
    "y = pd.Series(iris['target'], name=target_name)\n",
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set is 89.47%\n"
     ]
    }
   ],
   "source": [
    "# 1. Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "# 2. Fit Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=7)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 3. Return test accuracy score\n",
    "acc_test_score = rf_clf.score(X_test, y_test)\n",
    "print(f'Model accuracy on test set is {acc_test_score*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred      actual\n",
       "106  versicolor   virginica\n",
       "77    virginica  versicolor\n",
       "70    virginica  versicolor\n",
       "119  versicolor   virginica"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dict mapping index-to-target\n",
    "idx_to_target = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "#idx_to_target = {k: v for k, v in enumerate(iris.target_names)}\n",
    "\n",
    "# Let's see what observations our model incorrectly classified\n",
    "df_pred = pd.DataFrame({'pred': rf_clf.predict(X_test), 'actual': y_test}) \\\n",
    "            .replace(idx_to_target)\n",
    "df_pred[df_pred['pred'] != df_pred['actual']]\n",
    "# Model misclassifies couple of instances of virginica for versicolor and vice-versa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Model as Joblib File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_clf.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model Random Forest Classifier Model\n",
    "dump(rf_clf, 'rf_clf.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the Random Forest Classifier Model\n",
    "# rf_clf = load('rf_clf.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model Predictions in dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "versicolor\n",
      "versicolor\n"
     ]
    }
   ],
   "source": [
    "# Making model prediction with ONLY values\n",
    "\n",
    "### Returns target_name index\n",
    "pred_idx = rf_clf.predict([[2.5, 1.5, 3.5, 6.9]])[0]\n",
    "print(pred_idx)\n",
    "\n",
    "### Returns target_name\n",
    "# Method 2\n",
    "pred_target_name = iris.target_names[pred_idx]\n",
    "print(pred_target_name)\n",
    "\n",
    "# Method 2\n",
    "print(idx_to_target[pred_idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to parse features from json request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "def parse_args(requested_dict):\n",
    "  x_list = []\n",
    "  for feature in FEATURES:\n",
    "    value = requested_dict.get(feature, None)\n",
    "    if value: \n",
    "      x_list.append(value)\n",
    "    else:\n",
    "      x_list.append(0)\n",
    "  return x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.4, 6.1, 1.2, 4.3]\n",
      "[8.4, 0, 0, 4.3]\n"
     ]
    }
   ],
   "source": [
    "# Example of running parse_args function\n",
    "### (1) No missing features\n",
    "data = {'sepal length': 8.4, 'sepal width': 6.1, 'petal length': 1.2, 'petal width': 4.3}\n",
    "print(parse_args(data))\n",
    "\n",
    "### With missing features\n",
    "data = {'sepal length': 8.4, 'petal width': 4.3}\n",
    "print(parse_args(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load joblib model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PREDICTION': 'virginica'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = load('rf_clf.joblib')\n",
    "\n",
    "x_list = parse_args(data)\n",
    "x_array = np.array([x_list])\n",
    "\n",
    "pred = idx_to_target[MODEL.predict(x_array)[0]]\n",
    "response = {'PREDICTION': pred}\n",
    "json.loads(json.dumps(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3187107d9bae530a9730ce9d9da485a204d048878b7e1a8c1163a04ffe0ea8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
